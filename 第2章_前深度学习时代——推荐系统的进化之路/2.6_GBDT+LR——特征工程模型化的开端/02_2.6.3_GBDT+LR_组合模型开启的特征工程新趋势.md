# 02_2.6.3 GBDT+LR 组合模型开启的特征工程新趋势

"""
Lecture: 第2章 前深度学习时代——推荐系统的进化之路/2.6 GBDT+LR——特征工程模型化的开端
Content: 02_2.6.3 GBDT+LR 组合模型开启的特征工程新趋势
"""

### 2.6.3 GBDT+LR 组合模型开启的特征工程新趋势

#### 背景介绍

在推荐系统的发展过程中，特征工程一直是影响模型性能的关键因素。传统的特征工程方法主要依赖于人工或半人工的特征组合和筛选，或者通过改造目标函数和模型结构来增强特征交叉能力。然而，这些方法都有各自的局限性和挑战。

#### GBDT+LR组合模型的引入

GBDT+LR组合模型的出现，标志着特征工程模型化的重要趋势。该组合模型由Facebook在2014年提出，通过GBDT进行特征筛选和组合，生成新的离散特征向量，然后将其作为LR模型的输入，进行点击率预估。这种方法有效地解决了传统特征工程方法中的诸多问题。

#### 特征工程的新趋势

1. **自动化特征工程**：
   - 通过GBDT自动进行特征选择和组合，减少了人工特征工程的复杂度和工作量，提高了模型的表现和效率。GBDT作为一种集成学习方法，通过多棵决策树的集成来捕捉特征之间的复杂关系，并生成新的特征表示。

2. **端到端训练**：
   - GBDT+LR组合模型的提出，实现了特征工程的端到端训练。这意味着整个模型的输入可以是原始特征向量，而无需在特征工程上投入大量的人力和时间。这种方法不仅简化了模型训练的流程，还提高了特征工程的效率和效果。

3. **特征工程模型化的延续**：
   - 广义上讲，深度学习模型通过各类网络结构和嵌入层（Embedding）等方法完成特征工程的自动化，都是GBDT+LR组合模型开启的特征工程模型化趋势的延续。通过神经网络的嵌入层，特征可以自动进行高效的表示学习，从而提升模型的性能。

#### 优缺点分析

1. **优点**：
   - **高效的特征选择和组合**：GBDT能够高效地选择和组合特征，生成新的特征表示，提升模型的预测能力。
   - **减少人工干预**：通过自动化特征工程，减少了对算法工程师经验和精力的依赖，使得特征工程更加高效和便捷。
   - **端到端训练**：实现了从原始特征向量到模型输入的端到端训练，简化了模型训练的流程。

2. **缺点**：
   - **计算复杂度高**：GBDT的训练和特征转换过程需要大量的计算资源，尤其是处理大规模数据时，计算复杂度较高。
   - **过拟合风险**：由于GBDT强大的特征选择和组合能力，容易在训练数据上产生过拟合，需要通过适当的正则化和超参数调节来缓解。

#### 实际应用与挑战

1. **超参数调节**：
   - 在GBDT+LR组合模型中，GBDT子树的规模是一个关键的超参数。Facebook的研究显示，当子树规模超过500棵时，增加子树规模对损失下降的贡献微乎其微。最终，Facebook在实际应用中选择了600作为子树规模。

2. **模型实时性**：
   - 为了兼顾模型的实时性和复杂度，Facebook采取了“GBDT部分几天更新一次，LR部分准实时更新”的策略。这种局部更新的方法既能充分利用GBDT的特征处理能力，又能快速捕捉数据的动态变化。

#### 总结

GBDT+LR组合模型的提出，开启了特征工程模型化的新趋势，通过自动化特征选择和组合，实现了端到端的模型训练。这种方法不仅提高了模型的性能，还简化了特征工程的流程。尽管存在一定的计算复杂度和过拟合风险，但通过合理的超参数调节和优化策略，可以在实际应用中获得显著的效果。未来，随着计算资源的提升和模型优化技术的进步，GBDT+LR组合模型有望在更多的推荐系统中得到广泛应用。