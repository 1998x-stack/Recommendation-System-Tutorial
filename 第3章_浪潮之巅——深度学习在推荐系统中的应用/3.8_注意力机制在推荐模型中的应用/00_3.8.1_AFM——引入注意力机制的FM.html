
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>00_3.8.1_AFM——引入注意力机制的FM</title>
  <link rel="stylesheet" href="style.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">
</head>
<body>
  <div class="container">
    <h1>00_3.8.1 AFM——引入注意力机制的FM</h1>
<p>&quot;&quot;&quot;
Lecture: 第3章 浪潮之巅——深度学习在推荐系统中的应用/3.8 注意力机制在推荐模型中的应用
Content: 00_3.8.1 AFM——引入注意力机制的FM
&quot;&quot;&quot;</p>
<h3>3.8.1 AFM——引入注意力机制的FM</h3>
<h4>1. 背景和动机</h4>
<p>推荐系统中的Factorization Machines（FM）模型因其在处理稀疏数据和捕捉特征交互方面的优势而被广泛应用。然而，FM模型对所有的交叉特征一视同仁，这种加和池化（Sum Pooling）操作忽略了不同特征对结果的影响程度。为了解决这一问题，研究人员引入了注意力机制，提出了AFM（Attention-based Factorization Machine）模型。</p>
<h4>2. AFM模型概述</h4>
<p>AFM模型是在NFM（Neural Factorization Machine）模型的基础上发展而来的。NFM模型通过特征交叉池化层实现特征交互，但池化操作一视同仁地对待所有特征交互。AFM模型通过引入注意力机制，为每个特征交互分配不同的权重，从而保留了更多有价值的信息。</p>
<h4>3. 注意力机制的引入</h4>
<p>在AFM模型中，注意力机制通过一个注意力网络（Attention Net）实现。具体来说，AFM的特征交叉过程仍然采用元素积操作，但在池化过程中加入了注意力得分。注意力得分由一个简单的单全连接层和softmax输出层生成。假设两个特征向量的元素积为$$v_i \odot v_j$$，其注意力得分表示为$$a_{ij}$$。池化后的输出向量表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></msubsup><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></msubsup><msub><mi>a</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>(</mo><msub><mi>v</mi><mi>i</mi></msub><mo>⊙</mo><msub><mi>v</mi><mi>j</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">\sum_{i=1}^{n} \sum_{j=i+1}^{n} a_{ij} (v_i \odot v_j) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.6513970000000007em;"></span><span class="strut bottom" style="height:3.0651740000000007em;vertical-align:-1.4137769999999998em;"></span><span class="base displaystyle textstyle uncramped"><span class="mop op-limits"><span class="vlist"><span style="top:1.1776689999999999em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span><span style="top:-0.000005000000000143778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span><span class="op-symbol large-op mop">∑</span></span></span><span style="top:-1.2500050000000003em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">n</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mop op-limits"><span class="vlist"><span style="top:1.1776689999999999em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.05724em;">j</span><span class="mrel">=</span><span class="mord mathit">i</span><span class="mbin">+</span><span class="mord mathrm">1</span></span></span></span><span style="top:-0.000005000000000254801em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span><span class="op-symbol large-op mop">∑</span></span></span><span style="top:-1.2500050000000005em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">n</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord"><span class="mord mathit">a</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.05724em;">j</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">v</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">⊙</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">v</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.05724em;">j</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>这种加权的池化方式，可以更好地反映不同特征交互对结果的重要性。</p>
<h4>4. 注意力机制的实现</h4>
<p>具体地，AFM模型引入注意力机制的步骤如下：</p>
<ol>
<li><strong>特征交叉</strong>：与NFM模型类似，AFM模型首先对特征向量进行元素积操作，生成交叉特征。</li>
<li><strong>生成注意力得分</strong>：通过一个单全连接层和softmax层，计算每个交叉特征的注意力得分。</li>
<li><strong>加权池化</strong>：将交叉特征与对应的注意力得分相乘，进行加权池化，得到池化后的特征向量。</li>
<li><strong>输出层</strong>：将加权池化后的特征向量输入到最终的输出层，进行目标值的预测。</li>
</ol>
<h4>5. AFM模型的优势</h4>
<p>AFM模型相比传统的FM模型和其他基于FM的深度学习模型，具有以下优势：</p>
<ol>
<li><strong>增强的特征交互能力</strong>：通过引入注意力机制，AFM模型能够更有效地捕捉重要的特征交互，提升模型的表达能力。</li>
<li><strong>更强的非线性特征表示</strong>：注意力机制使得模型在特征交互时具有更强的非线性表达能力，能够更好地适应复杂的推荐场景。</li>
<li><strong>自动特征加权</strong>：注意力机制能够自动为不同特征交互分配权重，减少了人工特征工程的工作量，提高了模型的灵活性和适应性。</li>
<li><strong>高训练效率</strong>：与其他模型相比，AFM模型在保持高表达能力的同时，仍具有较高的训练效率。</li>
</ol>
<h4>6. 实验结果与分析</h4>
<p>实验结果表明，AFM模型在多个推荐任务中表现优异。在点击率预测和评分预测等任务中，AFM模型能够显著提升预测精度，优于传统的FM模型和其他基于FM的深度学习模型。</p>
<h4>7. 总结</h4>
<p>AFM模型通过引入注意力机制，改进了传统FM模型在特征交互处理上的局限性。其创新点在于为每个交叉特征分配不同的权重，使得模型能够更好地捕捉重要的特征交互信息。AFM模型在推荐系统中展示了强大的性能优势，不仅提升了模型的表达能力和预测精度，还减少了人工特征工程的工作量。通过上述分析，我们可以更深入地理解AFM模型的结构和其在推荐系统中的应用价值，为进一步的研究和实践提供了坚实的理论基础。</p>

  </div>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
        delimiters: [
          {left: "$$", right: "$$", display: true},
          {left: "$", right: "$", display: false},
          {left: "\(", right: "\)", display: false},
          {left: "\[", right: "\]", display: true}
        ]
      });
    });
  </script>
</body>
</html>
  