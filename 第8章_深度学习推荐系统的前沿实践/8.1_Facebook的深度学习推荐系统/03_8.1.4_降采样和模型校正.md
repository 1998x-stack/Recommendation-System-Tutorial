# 03_8.1.4 降采样和模型校正

"""
Lecture: 第8章 深度学习推荐系统的前沿实践/8.1 Facebook的深度学习推荐系统
Content: 03_8.1.4 降采样和模型校正
"""

### 8.1.4 降采样和模型校正

#### 背景与概述

在推荐系统的CTR（点击率）预估中，数据规模庞大且正负样本不均衡，给模型的训练和预测带来了挑战。为了控制数据规模和提高训练效率，Facebook采用了两种降采样方法：均匀采样（uniform subsampling）和负样本降采样（negative down sampling）。本文将详细探讨这两种降采样方法及其在模型校正中的应用。

#### 均匀采样

均匀采样是一种对所有样本进行无差别随机抽样的方法。Facebook通过实验比较了不同采样频率下训练模型的损失，并得出了最优的采样频率。

1. **采样频率的选择**：
   - Facebook试验了1%、10%、50%、100%四个采样频率。
   - 图8-3显示，不同采样频率下的模型损失变化情况。
   - 结果表明，当采样频率为10%时，模型损失仅上升了1%，而当采样频率降低到1%时，模型损失大幅上升了9%左右。因此，10%的采样频率被认为是平衡工程消耗和理论最优的最佳选择。

2. **应用效果**：
   - 均匀采样方法在实际应用中，显著降低了训练数据的规模，减少了计算资源的消耗，同时保证了模型的预测精度和效果。

#### 负样本降采样

负样本降采样是指保留全量正样本，对负样本进行降采样。此方法不仅提高了训练效率，还直接解决了正负样本不均衡的问题。

1. **采样频率的选择**：
   - Facebook经验性地选择了从0.0001到0.1的负采样频率。
   - 图8-4显示，不同负采样频率下的模型损失变化情况。
   - 结果表明，当负采样频率为0.0250时，模型损失不仅小于基于更低采样频率训练的模型，还小于负采样频率为0.1时训练的模型。这可能是由于通过解决数据不均衡问题带来的效果提升。在实际应用中，Facebook采用了0.0250的负采样频率。

2. **问题与校正**：
   - 负采样带来的问题是CTR预估值的漂移。例如，假设真实CTR是0.1%，进行0.01的负采样后，CTR将攀升到10%左右。
   - 为了进行准确的竞价及ROI预估，CTR预估模型需要提供准确的、有物理意义的CTR值。因此在进行负采样后需要进行CTR的校正，使CTR模型的预估值的期望回到0.1%。校正的公式如下：
     $$
     q = \frac{p}{w}
     $$
     其中，$ q $是校正后的CTR，$ p $是模型的预估CTR，$ w $是负采样频率。

#### 实际应用案例

**1. 广告推荐**：
- 在广告推荐系统中，负样本降采样方法显著提高了CTR预估模型的训练效率和预测准确性。通过对负样本的降采样，模型能够更好地处理正负样本不均衡的问题，提供更精确的点击率预估，优化广告投放策略，提高广告效果。

**2. 新闻推荐**：
- 在新闻推荐系统中，通过均匀采样和负样本降采样方法，模型能够高效地处理海量用户行为数据，提高新闻推荐的实时性和准确性。通过合理的采样策略，保证了模型的预测效果和系统的稳定性。

#### 优势与挑战

**优势**：
1. **数据规模控制**：通过降采样方法，有效控制了数据规模，降低了训练成本。
2. **训练效率提升**：降采样方法提高了模型的训练效率，缩短了训练时间。
3. **样本不均衡问题解决**：负样本降采样方法有效解决了正负样本不均衡的问题，提高了模型的预测准确性。

**挑战**：
1. **采样频率选择**：需要根据实际应用场景，合理选择采样频率，平衡数据规模和模型效果。
2. **模型校正**：降采样后，需要进行模型校正，以确保CTR预估值的准确性和物理意义。

#### 结论

通过均匀采样和负样本降采样方法，Facebook在推荐系统中有效控制了数据规模，提高了模型的训练效率和预测准确性。这两种方法在广告推荐、新闻推荐等应用场景中表现出色，为其他推荐系统提供了宝贵的经验和参考。在未来的研究和应用中，可以进一步优化采样策略和模型校正方法，提升推荐系统的整体性能和效果。